{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbe1bab1-a194-4686-a249-ee34a015c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4a7e29c6-899d-4c8b-961e-a0cf03f67ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, **params):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dim = params['dim']\n",
    "        self.expansion = params['expansion']\n",
    "        self.num_classes = params['num_classes']\n",
    "        \n",
    "        # parameters from resnet paper\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=self.dim, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # bottleneck layers\n",
    "        self.layer1 = self._build_layer(num_layers=3, out_dim=64, stride=1, padding=1) \n",
    "        self.layer2 = self._build_layer(num_layers=4, out_dim=128, stride=2, padding=1)\n",
    "        self.layer3 = self._build_layer(num_layers=6, out_dim=256, stride=2, padding=1)\n",
    "        self.layer4 = self._build_layer(num_layers=3, out_dim=512, stride=2, padding=1)\n",
    "        \n",
    "        # pool/fc\n",
    "        self.adapool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.adapool(x)\n",
    "        x = x.flatten(1)\n",
    "        out = self.fc(x)\n",
    "        \n",
    "        return out\n",
    "         \n",
    "    def _build_layer(self, num_layers, out_dim, stride, padding):\n",
    "        '''\n",
    "        layer1: (no image reduction)\n",
    "            in_dim: 64\n",
    "            out_dim: 64\n",
    "            stride: 1\n",
    "            padding: 0\n",
    "        \n",
    "        layer2: 56 -> 28\n",
    "            in_dim: 256\n",
    "            out_dim: 128\n",
    "            stride: 2\n",
    "            padding: 1\n",
    "            \n",
    "        layer3: 28 -> 14\n",
    "            in_dim: 516\n",
    "            out_dim: 256\n",
    "            stride; 2\n",
    "            padding: 1\n",
    "        \n",
    "        layer4: 14 -> 7\n",
    "            in_dim: 1028\n",
    "            out_dim: 512\n",
    "            stride: 2\n",
    "            padding: 1\n",
    "            \n",
    "        AdaptiveAvgPool2d: 7 -> 1\n",
    "        '''\n",
    "        # apply stride (image shape reduction) in first bottleneck block of each layer\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            Bottleneck(in_dim=self.dim, out_dim=out_dim, expansion=self.expansion, stride=stride, padding=padding, downsample=True)\n",
    "        )\n",
    "        \n",
    "        self.dim = self.expansion * out_dim # dimension expansion\n",
    "        for i in range(1, num_layers):\n",
    "            layers.append(\n",
    "                Bottleneck(in_dim=self.dim, out_dim=out_dim, expansion=self.expansion, stride=1, padding=padding)\n",
    "            )\n",
    "            \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "724e82f3-ee13-4fca-aeb5-abf15f41d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch bottleneck architecture applies stride in conv3x3 with stride=2 and padding=1\n",
    "# other architectures apply stride in 1st conv1x1 with stride=2 and padding=0\n",
    "\n",
    "# apply stride (image shape reduction) in first bottleneck block of each layer\n",
    "\n",
    "# bottleneck architecture: \n",
    "    # conv1x1 dimension reduction\n",
    "    # conv3x3 image shape reduction\n",
    "    # conv1x1 dimension expansion\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, expansion, stride, padding, downsample=False):\n",
    "        super().__init__()\n",
    "        self.expansion = expansion\n",
    "        \n",
    "        # layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_dim, out_channels=out_dim, kernel_size=1, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_dim)\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_dim, out_channels=out_dim, kernel_size=3, stride=stride, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm2d(out_dim)\n",
    "        self.conv3 = nn.Conv2d(in_channels=out_dim, out_channels=out_dim * self.expansion, kernel_size=1, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(out_dim * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = nn.Identity()\n",
    "        if downsample:\n",
    "            self.downsample = nn.Conv2d(in_channels=in_dim, out_channels=out_dim * self.expansion, kernel_size=1, stride=stride)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        \n",
    "        identity = self.downsample(x) # identity mapping\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1d851760-4fad-4d4c-885f-09402c4ed91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim':64, 'expansion':4, 'num_classes':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "86a28d88-f8e1-46be-958a-0d2bed2745b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "431e4a44-9000-4464-b1aa-9c16d5fb5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d6c31f21-00ea-41d7-afbd-73635b48788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "77165a6d-7dc5-4cf6-a53c-e7954524a04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6292, -0.0895, -0.2372,  0.1850, -0.9448, -0.8124, -0.6230, -0.8094,\n",
       "          0.6364, -1.2386]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e822982d-9b50-472b-9ac3-9a32baa11160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
