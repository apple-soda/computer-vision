{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3886d3-4fb9-4717-a3ce-3dc18a58d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c02c929-700a-4632-931a-06f9c180f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c904504-61c8-4d00-b49b-59a10f1bfa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'input_channels':3, 'dim':768, 'hidden_dim':3072, 'patch_size':16, 'img_size':224, 'num_layers':12, \n",
    "          'dropout':0.0, 'attention_dropout':0.0, 'num_heads':12, 'fine_tune':10, 'num_classes':21843}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13af9f0c-eac9-46db-a387-1df66de402fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit.pls import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f9561d-0474-4285-be1c-0f372c03d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionTransformer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7404f2e-a576-4256-8312-9681732311f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8b9c08-ed7f-4346-9f5e-be65d18b0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34672955-46dd-4662-b3ec-fc1b37fd9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.CIFAR10('D:/Data/random/', transform=transform_train, train=True, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f7edcb-1b18-4943-b9da-191a4fdcc4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = torch.utils.data.random_split(data, [40000, 10000])\n",
    "trainloader = torch.utils.data.DataLoader(train, shuffle=True, batch_size=16, num_workers=4)\n",
    "valloader = torch.utils.data.DataLoader(val, shuffle=True, batch_size=16, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1754d37-f074-42f0-9188-de8582c81820",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78ad0b21-4dae-4c2d-bbd3-dca3fcbc319b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['patch_embed.weight', 'patch_embed.bias', 'ft.weight', 'ft.bias'], unexpected_keys=['norm.weight', 'norm.bias', 'patch_embed.proj.weight', 'patch_embed.proj.bias'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('lasthope.pth', map_location=device), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f8f53b7-a100-43c4-82b2-8b66ac20a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2fe9416-b227-4570-9343-dbc2b6b54bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x1f3e50ff6a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded7e8bb-1e40-464b-a715-983712c202aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (blocks): Sequential(\n",
       "    (0): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): EncoderBlock(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): MultiheadAttention2(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU()\n",
       "        (dropout_1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (dropout_2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): Linear(in_features=768, out_features=21843, bias=True)\n",
       "  (ft): Linear(in_features=21843, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a768c0-538f-486f-a3ea-413a543e2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "val_losses = []\n",
    "avg_training_losses = []\n",
    "avg_val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a5e2991-0f26-4012-a983-6f552b8cf72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss, epochs, trainloader, valloader, device):\n",
    "    avg_tloss, avg_vloss = [], []\n",
    "    for e in tqdm(range(epochs)):\n",
    "        t_loss, v_loss = [], []\n",
    "        for x, y in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x.float())\n",
    "            l = loss(y_pred, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            npl = l.detach().cpu().numpy()\n",
    "            t_loss.append(npl)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            for x, y in valloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x.float())\n",
    "                l = loss(y_pred, y)\n",
    "                \n",
    "                npl = l.detach().cpu().numpy()\n",
    "                v_loss.append(npl)\n",
    "    \n",
    "        avg_tloss.append(np.mean(t_loss))\n",
    "        avg_vloss.append(np.mean(v_loss))\n",
    "\n",
    "        print(f'Epoch: {e}, Training Loss: {np.mean(t_loss)}, Validation Loss: {np.mean(v_loss)}')\n",
    "    \n",
    "    return avg_tloss, avg_vloss, model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a3771-852c-4efc-b8dd-e90e0f82c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                              | 1/100 [13:40<22:34:13, 820.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 302.44830322265625, Validation Loss: 2.5833210945129395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                              | 2/100 [27:20<22:19:29, 820.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 1965.947998046875, Validation Loss: 19.663541793823242\n"
     ]
    }
   ],
   "source": [
    "tloss, vloss, model, optimizer = train(model, optimizer, loss, 100, trainloader, valloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
